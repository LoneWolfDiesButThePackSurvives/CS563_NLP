{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanza.models.common.constant import is_right_to_left\n",
    "import stanza\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "\n",
    "def visualize_doc(doc, pipeline):\n",
    "    \"\"\"\n",
    "    Takes in a Document and visualizes it using displacy. The document must be from the stanza pipeline.\n",
    "    Works for English inputs. The reverse_order parameter can be set as True to flip the display of the\n",
    "    words for languages such as Arabic, which are read from right-to-left.\n",
    "    \"\"\"\n",
    "    visualization_options = {\"compact\": True, \"bg\": \"#09a3d5\", \"color\": \"white\", \"distance\": 90,\n",
    "                             \"font\": \"Source Sans Pro\", \"arrow_spacing\": 25}\n",
    "    # blank model - we don't use any of the model features, just the viz\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    sentences_to_visualize = []\n",
    "    for sentence in doc.sentences:\n",
    "        words, lemmas, heads, deps, tags = [], [], [], [], []\n",
    "        if is_right_to_left(pipeline):  # order of words displayed is reversed, dependency arcs remain intact\n",
    "            sent_len = len(sentence.words)\n",
    "            for word in reversed(sentence.words):\n",
    "                words.append(word.text)\n",
    "                lemmas.append(word.lemma)\n",
    "                deps.append(word.deprel)\n",
    "                tags.append(word.upos)\n",
    "                if word.head == 0:  # spaCy head indexes are formatted differently than that of Stanza\n",
    "                    heads.append(sent_len - word.id)\n",
    "                else:\n",
    "                    heads.append(sent_len - word.head)\n",
    "        else:   # left to right rendering\n",
    "            for word in sentence.words:\n",
    "                words.append(word.text)\n",
    "                lemmas.append(word.lemma)\n",
    "                deps.append(word.deprel)\n",
    "                tags.append(word.upos)\n",
    "                if word.head == 0:\n",
    "                    heads.append(word.id - 1)\n",
    "                else:\n",
    "                    heads.append(word.head - 1)\n",
    "        document_result = Doc(nlp.vocab, words=words, lemmas=lemmas, heads=heads, deps=deps, pos=tags)\n",
    "        sentences_to_visualize.append(document_result)\n",
    "\n",
    "    for line in sentences_to_visualize:  # render all sentences through displaCy\n",
    "        # If this program is NOT being run in a Jupyter notebook, replace displacy.render with displacy.serve\n",
    "        # and the visualization will be hosted locally, link being provided in the program output.\n",
    "        displacy.render(line, style=\"dep\", options=visualization_options)\n",
    "\n",
    "\n",
    "def visualize_str(text, pipeline_code, pipe):\n",
    "    \"\"\"\n",
    "    Takes a string and visualizes it using displacy. The string is processed using the stanza pipeline and\n",
    "    its dependencies are formatted into a spaCy doc object for easy visualization. Accepts valid stanza (UD)\n",
    "    pipelines as the pipeline argument. Must supply the stanza pipeline code (the two-letter abbreviation of the\n",
    "    language, such as 'en' for English. Must also supply the stanza pipeline object as the third argument.\n",
    "    \"\"\"\n",
    "    doc = pipe(text)\n",
    "    visualize_doc(doc, pipeline_code)\n",
    "\n",
    "\n",
    "def visualize_docs(docs, lang_code):\n",
    "    \"\"\"\n",
    "    Takes in a list of Stanza document objects and a language code (ex: 'en' for English) and visualizes the\n",
    "    dependency relationships within each document. This function uses spaCy visualizations. See the visualize_doc\n",
    "    function for more details.\n",
    "    \"\"\"\n",
    "    for doc in docs:\n",
    "        visualize_doc(doc, lang_code)\n",
    "\n",
    "\n",
    "def visualize_strings(texts, lang_code):\n",
    "    \"\"\"\n",
    "    Takes a language code (ex: 'en' for English) and a list of strings to process and visualizes the \n",
    "    dependency relationships in each text. This function loads the Stanza pipeline for the given language \n",
    "    and uses it to visualize all of the strings provided.\n",
    "    \"\"\"\n",
    "    pipe = stanza.Pipeline(lang_code)\n",
    "    for text in texts:\n",
    "        visualize_str(text, lang_code, pipe)\n",
    "\n",
    "\n",
    "def main():\n",
    "    ar_strings = ['برلين ترفض حصول شركة اميركية على رخصة تصنيع دبابة \"ليوبارد\" الالمانية', \"هل بإمكاني مساعدتك؟\", \n",
    "               \"أراك في مابعد\", \"لحظة من فضلك\"]\n",
    "    en_strings = [\"This is a sentence.\", \n",
    "                  \"Barack Obama was born in Hawaii. He was elected President of the United States in 2008.\"]\n",
    "    zh_strings = [\"中国是一个很有意思的国家。\"]\n",
    "    # Testing with right to left language\n",
    "    visualize_strings(ar_strings, \"ar\")\n",
    "    # Testing with left to right languages\n",
    "    visualize_strings(en_strings, \"en\")\n",
    "    visualize_strings(zh_strings, \"zh\")\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf10ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
